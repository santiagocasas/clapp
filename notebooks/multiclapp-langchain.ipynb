{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_provider=\"openai\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke([HumanMessage(content=\"What's something interesting about whales?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "memory = ChatMessageHistory()\n",
    "\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../class-data/CLASS_MANUAL.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classy_instuctions = \"\"\"You are a retrieval-augmented assistant for the CLASS code, specifically focused on solving Einstein-Boltzmann equations. Your primary task is to use information retrieved from the CLASS code and its documentation to answer user queries accurately and concisely.\n",
    "\n",
    "Define key components or concepts related to the Einstein-Boltzmann solver in the CLASS code, then proceed through each detailed step to reach the solution.\n",
    "\n",
    "1. **Use Retrieved Context**: \n",
    "   - Incorporate retrieved information directly into your responses.\n",
    "   - Ensure your answers are specifically related to the Einstein-Boltzmann solver in the CLASS code.\n",
    "\n",
    "2. **Fallback to General Knowledge**:\n",
    "   - If specific retrieved data is missing, incomplete, or irrelevant:\n",
    "     - Inform the user about the insufficiency.\n",
    "     - Utilize general scientific knowledge to answer, specifying that itâ€™s based on such information.\n",
    "\n",
    "3. **Handling Conflicting Information**:\n",
    "   - If retrieved documents contain conflicting information:\n",
    "     - Highlight discrepancies.\n",
    "     - Cite each source and provide a balanced response.\n",
    "\n",
    "4. **Clarification and Error Handling**:\n",
    "   - If the query is ambiguous, request clarification before answering.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Identify the Problem**: Clearly define the query related to Einstein-Boltzmann equations and identify important terms or components.\n",
    "2. **Break Down Steps**: Solve the problem step by step, considering mathematical and cosmological principles.\n",
    "3. **Reasoning**: Explain why each step is necessary before moving to the next one, using scientific reasoning.\n",
    "4. **Conclusion**: Present the final answer once all steps are explained and justified.\n",
    "\n",
    "# Output Format\n",
    "\n",
    "Provide concise, accurate responses in a scientific explanatory format. Make use of technical language relevant to Einstein-Boltzmann solvers.\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Focus on the cosmological and differential equation-solving aspects critical to understanding Einstein-Boltzmann solvers.\n",
    "- Precision in mathematical definitions and cosmological parameters is crucial.\n",
    "- Clearly distinguish between retrieved information and general knowledge when formulating responses.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke(context,question,system):\n",
    "    # Build structured messages\n",
    "\n",
    "    system = SystemMessage(content=system)\n",
    "    human = HumanMessage(content=f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "\n",
    "    # Combine memory with new messages\n",
    "    messages = [system] + memory.messages + [human]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(question):\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls:\n",
    "question = \"Can you give me an example of the temperature Cls in LCDM?\"\n",
    "memory.add_user_message(question)\n",
    "context = retrieve(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(invoke(context,question,Classy_instuctions))\n",
    "memory.add_ai_message(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls:\n",
    "question = \"Can you give me a classy example in python of how to plot this?\"\n",
    "memory.add_user_message(question)\n",
    "context = retrieve(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(invoke(context,question,Classy_instuctions))\n",
    "memory.add_ai_message(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
